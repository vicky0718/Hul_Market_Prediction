{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "930599d7",
   "metadata": {},
   "source": [
    "# Competition-Aware S&P 500 Position Optimization\n",
    "\n",
    "## Overview\n",
    "This notebook implements models that optimize directly for the competition metric: a volatility-adjusted Sharpe ratio that penalizes excess volatility and poor returns.\n",
    "\n",
    "**Key Changes from Baseline:**\n",
    "- **Target**: Optimal positions (0-2) instead of return predictions\n",
    "- **Loss Function**: Competition metric (adjusted Sharpe ratio)\n",
    "- **Features**: Full feature set from imputed data\n",
    "- **Evaluation**: Risk-adjusted performance metrics\n",
    "- **Strategy**: Portfolio optimization, not prediction accuracy\n",
    "\n",
    "**Competition Metric:**\n",
    "```\n",
    "adjusted_sharpe = sharpe_ratio / (volatility_penalty * return_penalty)\n",
    "```\n",
    "\n",
    "Where:\n",
    "- `volatility_penalty = 1 + max(0, strategy_vol/market_vol - 1.2)`\n",
    "- `return_penalty = 1 + (max(0, market_return - strategy_return) * 100 * 252)¬≤/100`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714b28de",
   "metadata": {},
   "source": [
    "## 1. Setup and Competition Metric Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae8e2a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Advanced models (XGBoost, LightGBM) available\n",
      "‚úÖ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array\n",
    "\n",
    "# Advanced models\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    import lightgbm as lgb\n",
    "    ADVANCED_MODELS = True\n",
    "    print(\"‚úÖ Advanced models (XGBoost, LightGBM) available\")\n",
    "except ImportError:\n",
    "    ADVANCED_MODELS = False\n",
    "    print(\"‚ö†Ô∏è Advanced models not available\")\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a98a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Competition metric functions implemented\n"
     ]
    }
   ],
   "source": [
    "# Implement the competition metric exactly as provided\n",
    "def calculate_competition_metric(positions, forward_returns, risk_free_rates, verbose=False):\n",
    "    \"\"\"\n",
    "    Calculate the competition's volatility-adjusted Sharpe ratio.\n",
    "    \n",
    "    Args:\n",
    "        positions: Array of position weights (0-2)\n",
    "        forward_returns: Array of market forward returns\n",
    "        risk_free_rates: Array of risk-free rates\n",
    "        verbose: Print detailed calculations\n",
    "    \n",
    "    Returns:\n",
    "        float: Adjusted Sharpe ratio (competition metric)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure arrays\n",
    "    positions = np.array(positions)\n",
    "    forward_returns = np.array(forward_returns)\n",
    "    risk_free_rates = np.array(risk_free_rates)\n",
    "    \n",
    "    # Validate position constraints\n",
    "    MIN_INVESTMENT = 0\n",
    "    MAX_INVESTMENT = 2\n",
    "    \n",
    "    if positions.max() > MAX_INVESTMENT or positions.min() < MIN_INVESTMENT:\n",
    "        if verbose:\n",
    "            print(f\"‚ö†Ô∏è Position constraint violation: [{positions.min():.4f}, {positions.max():.4f}]\")\n",
    "        return -1000  # Heavy penalty for constraint violation\n",
    "    \n",
    "    # Calculate strategy returns\n",
    "    strategy_returns = risk_free_rates * (1 - positions) + positions * forward_returns\n",
    "    \n",
    "    # Calculate strategy's Sharpe ratio\n",
    "    strategy_excess_returns = strategy_returns - risk_free_rates\n",
    "    strategy_excess_cumulative = (1 + strategy_excess_returns).prod()\n",
    "    strategy_mean_excess_return = strategy_excess_cumulative ** (1 / len(strategy_returns)) - 1\n",
    "    strategy_std = strategy_returns.std()\n",
    "    \n",
    "    trading_days_per_yr = 252\n",
    "    \n",
    "    if strategy_std == 0:\n",
    "        return -1000  # Penalty for zero volatility\n",
    "    \n",
    "    sharpe = strategy_mean_excess_return / strategy_std * np.sqrt(trading_days_per_yr)\n",
    "    strategy_volatility = float(strategy_std * np.sqrt(trading_days_per_yr) * 100)\n",
    "    \n",
    "    # Calculate market return and volatility\n",
    "    market_excess_returns = forward_returns - risk_free_rates\n",
    "    market_excess_cumulative = (1 + market_excess_returns).prod()\n",
    "    market_mean_excess_return = market_excess_cumulative ** (1 / len(forward_returns)) - 1\n",
    "    market_std = forward_returns.std()\n",
    "    market_volatility = float(market_std * np.sqrt(trading_days_per_yr) * 100)\n",
    "    \n",
    "    if market_volatility == 0:\n",
    "        return -1000  # Penalty for zero market volatility\n",
    "    \n",
    "    # Calculate the volatility penalty\n",
    "    excess_vol = max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n",
    "    vol_penalty = 1 + excess_vol\n",
    "    \n",
    "    # Calculate the return penalty\n",
    "    return_gap = max(\n",
    "        0,\n",
    "        (market_mean_excess_return - strategy_mean_excess_return) * 100 * trading_days_per_yr,\n",
    "    )\n",
    "    return_penalty = 1 + (return_gap**2) / 100\n",
    "    \n",
    "    # Adjust the Sharpe ratio by the volatility and return penalty\n",
    "    adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"üìä Competition Metric Breakdown:\")\n",
    "        print(f\"   ‚Ä¢ Strategy Sharpe: {sharpe:.4f}\")\n",
    "        print(f\"   ‚Ä¢ Strategy Volatility: {strategy_volatility:.2f}%\")\n",
    "        print(f\"   ‚Ä¢ Market Volatility: {market_volatility:.2f}%\")\n",
    "        print(f\"   ‚Ä¢ Volatility Penalty: {vol_penalty:.4f}\")\n",
    "        print(f\"   ‚Ä¢ Return Penalty: {return_penalty:.4f}\")\n",
    "        print(f\"   ‚Ä¢ Adjusted Sharpe: {adjusted_sharpe:.4f}\")\n",
    "    \n",
    "    return min(float(adjusted_sharpe), 1_000_000)\n",
    "\n",
    "# Additional helper functions\n",
    "def calculate_hit_rate(y_true, y_pred):\n",
    "    \"\"\"Calculate directional accuracy\"\"\"\n",
    "    return np.mean(np.sign(y_true) == np.sign(y_pred))\n",
    "\n",
    "def calculate_strategy_volatility(positions, forward_returns, risk_free_rates):\n",
    "    \"\"\"Calculate annualized strategy volatility\"\"\"\n",
    "    strategy_returns = risk_free_rates * (1 - positions) + positions * forward_returns\n",
    "    return strategy_returns.std() * np.sqrt(252) * 100\n",
    "\n",
    "def calculate_strategy_return(positions, forward_returns, risk_free_rates):\n",
    "    \"\"\"Calculate annualized strategy return\"\"\"\n",
    "    strategy_returns = risk_free_rates * (1 - positions) + positions * forward_returns\n",
    "    cumulative_return = (1 + strategy_returns).prod()\n",
    "    return (cumulative_return ** (252 / len(strategy_returns)) - 1) * 100\n",
    "\n",
    "print(\"‚úÖ Competition metric functions implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e955e93",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d221a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä LOADING DATASETS\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Clean training data loaded: (8990, 100)\n",
      "   ‚Ä¢ Missing values: 110,204\n",
      "‚úÖ Test data loaded: (10, 99)\n",
      "   ‚Ä¢ Missing values: 0\n",
      "‚úÖ All required columns present\n",
      "\n",
      "üìã Available targets: ['forward_returns', 'risk_free_rate', 'market_forward_excess_returns']\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "print(\"üìä LOADING DATASETS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load clean imputed training data (our best shot at good features)\n",
    "try:\n",
    "    df_train_imputed = pd.read_csv('../data/cleaned/train_imputed.csv')\n",
    "    print(f\"‚úÖ Clean training data loaded: {df_train_imputed.shape}\")\n",
    "    print(f\"   ‚Ä¢ Missing values: {df_train_imputed.isnull().sum().sum():,}\")\n",
    "    USE_IMPUTED = True\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è Clean imputed data not found, using original training data\")\n",
    "    df_train_imputed = pd.read_csv('../data/raw/train.csv')\n",
    "    USE_IMPUTED = False\n",
    "\n",
    "# Load test data\n",
    "df_test = pd.read_csv('../data/raw/test.csv')\n",
    "print(f\"‚úÖ Test data loaded: {df_test.shape}\")\n",
    "print(f\"   ‚Ä¢ Missing values: {df_test.isnull().sum().sum():,}\")\n",
    "\n",
    "# Check for required columns\n",
    "required_cols = ['forward_returns', 'risk_free_rate']\n",
    "missing_cols = [col for col in required_cols if col not in df_train_imputed.columns]\n",
    "\n",
    "if missing_cols:\n",
    "    print(f\"‚ùå Missing required columns: {missing_cols}\")\n",
    "    # Try alternative names\n",
    "    if 'market_forward_excess_returns' in df_train_imputed.columns:\n",
    "        print(\"   Using market_forward_excess_returns as proxy for forward_returns\")\n",
    "        if 'forward_returns' not in df_train_imputed.columns:\n",
    "            df_train_imputed['forward_returns'] = df_train_imputed['market_forward_excess_returns']\n",
    "else:\n",
    "    print(f\"‚úÖ All required columns present\")\n",
    "\n",
    "print(f\"\\nüìã Available targets: {[col for col in df_train_imputed.columns if 'return' in col.lower() or 'rate' in col.lower()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70afa619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß FEATURE ENGINEERING\n",
      "==================================================\n",
      "üìä Feature Analysis:\n",
      "   ‚Ä¢ Training features: 96\n",
      "   ‚Ä¢ Test features: 94\n",
      "   ‚Ä¢ Common features: 94\n",
      "\n",
      "üìà Feature Categories:\n",
      "   ‚Ä¢ D_features: 9 features\n",
      "   ‚Ä¢ E_features: 20 features\n",
      "   ‚Ä¢ I_features: 9 features\n",
      "   ‚Ä¢ M_features: 18 features\n",
      "   ‚Ä¢ P_features: 13 features\n",
      "   ‚Ä¢ S_features: 12 features\n",
      "   ‚Ä¢ V_features: 13 features\n",
      "\n",
      "üéØ Strategic Feature Sets:\n",
      "   ‚Ä¢ all_features: 94 features\n",
      "   ‚Ä¢ volatility_focused: 31 features\n",
      "   ‚Ä¢ price_focused: 33 features\n",
      "   ‚Ä¢ binary_signals: 9 features\n",
      "   ‚Ä¢ top_50: 50 features\n",
      "\n",
      "‚úÖ Feature engineering complete!\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering and preparation\n",
    "print(\"üîß FEATURE ENGINEERING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define feature categories based on test data structure\n",
    "exclude_cols = ['date_id', 'forward_returns', 'market_forward_excess_returns', 'risk_free_rate', \n",
    "                'lagged_forward_returns', 'lagged_risk_free_rate', 'lagged_market_forward_excess_returns',\n",
    "                'is_scored']\n",
    "\n",
    "# Get feature columns that exist in both train and test\n",
    "train_features = [col for col in df_train_imputed.columns if col not in exclude_cols]\n",
    "test_features = [col for col in df_test.columns if col not in exclude_cols]\n",
    "common_features = list(set(train_features) & set(test_features))\n",
    "\n",
    "print(f\"üìä Feature Analysis:\")\n",
    "print(f\"   ‚Ä¢ Training features: {len(train_features)}\")\n",
    "print(f\"   ‚Ä¢ Test features: {len(test_features)}\")\n",
    "print(f\"   ‚Ä¢ Common features: {len(common_features)}\")\n",
    "\n",
    "# Categorize features by type\n",
    "feature_categories = {\n",
    "    'D_features': [f for f in common_features if f.startswith('D')],\n",
    "    'E_features': [f for f in common_features if f.startswith('E')],\n",
    "    'I_features': [f for f in common_features if f.startswith('I')],\n",
    "    'M_features': [f for f in common_features if f.startswith('M')],\n",
    "    'P_features': [f for f in common_features if f.startswith('P')],\n",
    "    'S_features': [f for f in common_features if f.startswith('S')],\n",
    "    'V_features': [f for f in common_features if f.startswith('V')]\n",
    "}\n",
    "\n",
    "print(f\"\\nüìà Feature Categories:\")\n",
    "for category, features in feature_categories.items():\n",
    "    print(f\"   ‚Ä¢ {category}: {len(features)} features\")\n",
    "    if len(features) <= 5:\n",
    "        print(f\"     {features}\")\n",
    "\n",
    "# Create strategic feature sets for position optimization\n",
    "feature_sets = {\n",
    "    'all_features': common_features,\n",
    "    'volatility_focused': feature_categories['V_features'] + feature_categories['M_features'],\n",
    "    'price_focused': feature_categories['P_features'] + feature_categories['E_features'],\n",
    "    'binary_signals': feature_categories['D_features'],\n",
    "    'top_50': common_features[:50] if len(common_features) >= 50 else common_features\n",
    "}\n",
    "\n",
    "# Filter out empty feature sets\n",
    "feature_sets = {name: features for name, features in feature_sets.items() if len(features) > 0}\n",
    "\n",
    "print(f\"\\nüéØ Strategic Feature Sets:\")\n",
    "for name, features in feature_sets.items():\n",
    "    print(f\"   ‚Ä¢ {name}: {len(features)} features\")\n",
    "\n",
    "print(f\"\\n‚úÖ Feature engineering complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d03402",
   "metadata": {},
   "source": [
    "## 3. Competition-Aware Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e706138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Competition-aware regressor implemented\n",
      "‚úÖ Created 7 competition-aware models\n",
      "   ‚Ä¢ Comp_Ridge\n",
      "   ‚Ä¢ Comp_Lasso\n",
      "   ‚Ä¢ Comp_ElasticNet\n",
      "   ‚Ä¢ Comp_RandomForest\n",
      "   ‚Ä¢ Comp_GradientBoosting\n",
      "   ‚Ä¢ Comp_XGBoost\n",
      "   ‚Ä¢ Comp_LightGBM\n"
     ]
    }
   ],
   "source": [
    "# Create a custom regressor that optimizes for the competition metric\n",
    "class CompetitionAwareRegressor(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    A wrapper that trains any regressor to optimize portfolio positions\n",
    "    for the competition metric instead of prediction accuracy.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_estimator, position_bounds=(0, 2), alpha=0.1):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.position_bounds = position_bounds\n",
    "        self.alpha = alpha  # Regularization for extreme positions\n",
    "        \n",
    "    def fit(self, X, y, forward_returns=None, risk_free_rates=None):\n",
    "        \"\"\"\n",
    "        Fit the model. If forward_returns and risk_free_rates are provided,\n",
    "        we can try to optimize positions directly.\n",
    "        \"\"\"\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        # For simplicity, we'll train the base estimator on returns first\n",
    "        # Then convert predictions to optimal positions\n",
    "        self.base_estimator.fit(X, y)\n",
    "        \n",
    "        # Store training statistics for position scaling\n",
    "        predictions = self.base_estimator.predict(X)\n",
    "        self.prediction_std_ = np.std(predictions)\n",
    "        self.prediction_mean_ = np.mean(predictions)\n",
    "        \n",
    "        # If we have the required data, optimize position scaling\n",
    "        if forward_returns is not None and risk_free_rates is not None:\n",
    "            self._optimize_position_scaling(predictions, forward_returns, risk_free_rates)\n",
    "        else:\n",
    "            # Default scaling: center around 1.0 (100% market exposure)\n",
    "            self.position_scale_ = 1.0\n",
    "            self.position_offset_ = 1.0\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _optimize_position_scaling(self, predictions, forward_returns, risk_free_rates):\n",
    "        \"\"\"\n",
    "        Optimize the scaling from predictions to positions using the competition metric.\n",
    "        \"\"\"\n",
    "        best_score = -np.inf\n",
    "        best_scale = 1.0\n",
    "        best_offset = 1.0\n",
    "        \n",
    "        # Grid search over scaling parameters\n",
    "        scales = np.linspace(0.1, 3.0, 20)\n",
    "        offsets = np.linspace(0.5, 1.5, 15)\n",
    "        \n",
    "        for scale in scales:\n",
    "            for offset in offsets:\n",
    "                # Convert predictions to positions\n",
    "                positions = self._predictions_to_positions(predictions, scale, offset)\n",
    "                \n",
    "                # Calculate competition metric\n",
    "                try:\n",
    "                    score = calculate_competition_metric(positions, forward_returns, risk_free_rates)\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_scale = scale\n",
    "                        best_offset = offset\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        self.position_scale_ = best_scale\n",
    "        self.position_offset_ = best_offset\n",
    "        self.best_training_score_ = best_score\n",
    "    \n",
    "    def _predictions_to_positions(self, predictions, scale=None, offset=None):\n",
    "        \"\"\"\n",
    "        Convert model predictions to valid portfolio positions.\n",
    "        \"\"\"\n",
    "        if scale is None:\n",
    "            scale = self.position_scale_\n",
    "        if offset is None:\n",
    "            offset = self.position_offset_\n",
    "        \n",
    "        # Normalize predictions\n",
    "        if self.prediction_std_ > 0:\n",
    "            normalized = (predictions - self.prediction_mean_) / self.prediction_std_\n",
    "        else:\n",
    "            normalized = predictions - self.prediction_mean_\n",
    "        \n",
    "        # Scale and shift to position space\n",
    "        positions = offset + scale * normalized\n",
    "        \n",
    "        # Clip to valid range\n",
    "        positions = np.clip(positions, self.position_bounds[0], self.position_bounds[1])\n",
    "        \n",
    "        return positions\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict optimal portfolio positions.\n",
    "        \"\"\"\n",
    "        X = check_array(X)\n",
    "        \n",
    "        # Get base predictions\n",
    "        base_predictions = self.base_estimator.predict(X)\n",
    "        \n",
    "        # Convert to positions\n",
    "        positions = self._predictions_to_positions(base_predictions)\n",
    "        \n",
    "        return positions\n",
    "\n",
    "print(\"‚úÖ Competition-aware regressor implemented\")\n",
    "\n",
    "# Create model configurations optimized for position prediction\n",
    "def create_competition_models():\n",
    "    \"\"\"Create models optimized for the competition metric.\"\"\"\n",
    "    \n",
    "    base_models = {\n",
    "        'Ridge': Ridge(alpha=1.0, random_state=42),\n",
    "        'Lasso': Lasso(alpha=0.1, random_state=42, max_iter=2000),\n",
    "        'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42, max_iter=2000),\n",
    "        'RandomForest': RandomForestRegressor(\n",
    "            n_estimators=100, max_depth=8, random_state=42, n_jobs=-1\n",
    "        ),\n",
    "        'GradientBoosting': GradientBoostingRegressor(\n",
    "            n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    if ADVANCED_MODELS:\n",
    "        base_models['XGBoost'] = xgb.XGBRegressor(\n",
    "            n_estimators=100, learning_rate=0.1, max_depth=6, \n",
    "            random_state=42, verbosity=0\n",
    "        )\n",
    "        base_models['LightGBM'] = lgb.LGBMRegressor(\n",
    "            n_estimators=100, learning_rate=0.1, max_depth=6,\n",
    "            random_state=42, verbosity=-1\n",
    "        )\n",
    "    \n",
    "    # Wrap each base model with competition-aware wrapper\n",
    "    competition_models = {}\n",
    "    for name, model in base_models.items():\n",
    "        competition_models[f\"Comp_{name}\"] = CompetitionAwareRegressor(model)\n",
    "    \n",
    "    return competition_models\n",
    "\n",
    "models = create_competition_models()\n",
    "print(f\"‚úÖ Created {len(models)} competition-aware models\")\n",
    "for name in models.keys():\n",
    "    print(f\"   ‚Ä¢ {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f130c5f",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluation Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67b93607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä TRAINING DATA PREPARATION\n",
      "==================================================\n",
      "üìà Target Variable Analysis:\n",
      "   ‚Ä¢ Total samples: 8,990\n",
      "   ‚Ä¢ Valid samples: 8,990\n",
      "   ‚Ä¢ Missing targets: 0\n",
      "\n",
      "üìä Final Training Data:\n",
      "   ‚Ä¢ Samples: 8,990\n",
      "   ‚Ä¢ Forward returns range: [-0.039754, 0.040661]\n",
      "   ‚Ä¢ Risk-free rate range: [-0.000004, 0.000317]\n",
      "   ‚Ä¢ Forward returns std: 0.010551\n",
      "\n",
      "‚úÖ Training data prepared successfully!\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data\n",
    "print(\"üìä TRAINING DATA PREPARATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Ensure we have the required target variables\n",
    "if 'forward_returns' not in df_train_imputed.columns:\n",
    "    print(\"‚ùå forward_returns not found in training data!\")\n",
    "    available_targets = [col for col in df_train_imputed.columns if 'return' in col.lower()]\n",
    "    print(f\"Available targets: {available_targets}\")\n",
    "    if available_targets:\n",
    "        primary_target = available_targets[0]\n",
    "        print(f\"Using {primary_target} as proxy for forward_returns\")\n",
    "        df_train_imputed['forward_returns'] = df_train_imputed[primary_target]\n",
    "    else:\n",
    "        raise ValueError(\"No suitable target variable found!\")\n",
    "\n",
    "if 'risk_free_rate' not in df_train_imputed.columns:\n",
    "    print(\"‚ö†Ô∏è risk_free_rate not found, creating synthetic risk-free rate\")\n",
    "    # Use a small constant risk-free rate as approximation\n",
    "    df_train_imputed['risk_free_rate'] = 0.0001  # ~2.5% annualized\n",
    "\n",
    "# Extract target variables\n",
    "y_forward_returns = df_train_imputed['forward_returns'].copy()\n",
    "y_risk_free_rate = df_train_imputed['risk_free_rate'].copy()\n",
    "\n",
    "# Remove rows with missing targets\n",
    "valid_idx = (~y_forward_returns.isnull()) & (~y_risk_free_rate.isnull())\n",
    "print(f\"üìà Target Variable Analysis:\")\n",
    "print(f\"   ‚Ä¢ Total samples: {len(df_train_imputed):,}\")\n",
    "print(f\"   ‚Ä¢ Valid samples: {valid_idx.sum():,}\")\n",
    "print(f\"   ‚Ä¢ Missing targets: {(~valid_idx).sum():,}\")\n",
    "\n",
    "if valid_idx.sum() < len(df_train_imputed):\n",
    "    print(f\"   ‚Ä¢ Removing {(~valid_idx).sum()} samples with missing targets\")\n",
    "    df_train_clean = df_train_imputed[valid_idx].copy()\n",
    "    y_forward_returns = y_forward_returns[valid_idx]\n",
    "    y_risk_free_rate = y_risk_free_rate[valid_idx]\n",
    "else:\n",
    "    df_train_clean = df_train_imputed.copy()\n",
    "\n",
    "print(f\"\\nüìä Final Training Data:\")\n",
    "print(f\"   ‚Ä¢ Samples: {len(df_train_clean):,}\")\n",
    "print(f\"   ‚Ä¢ Forward returns range: [{y_forward_returns.min():.6f}, {y_forward_returns.max():.6f}]\")\n",
    "print(f\"   ‚Ä¢ Risk-free rate range: [{y_risk_free_rate.min():.6f}, {y_risk_free_rate.max():.6f}]\")\n",
    "print(f\"   ‚Ä¢ Forward returns std: {y_forward_returns.std():.6f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Training data prepared successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36093917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Competition evaluation function defined\n"
     ]
    }
   ],
   "source": [
    "# Competition-aware evaluation function\n",
    "def evaluate_competition_model(model, X_train, y_train, X_val, y_val, \n",
    "                             forward_returns_train, risk_free_train,\n",
    "                             forward_returns_val, risk_free_val,\n",
    "                             model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Evaluate a model using competition-specific metrics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Train the model with competition context\n",
    "        if hasattr(model, 'fit') and 'forward_returns' in model.fit.__code__.co_varnames:\n",
    "            # Competition-aware model\n",
    "            model.fit(X_train, y_train, \n",
    "                     forward_returns=forward_returns_train, \n",
    "                     risk_free_rates=risk_free_train)\n",
    "        else:\n",
    "            # Standard model\n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "        # Get position predictions\n",
    "        positions_train = model.predict(X_train)\n",
    "        positions_val = model.predict(X_val)\n",
    "        \n",
    "        # Calculate competition metrics\n",
    "        train_score = calculate_competition_metric(\n",
    "            positions_train, forward_returns_train, risk_free_train\n",
    "        )\n",
    "        val_score = calculate_competition_metric(\n",
    "            positions_val, forward_returns_val, risk_free_val\n",
    "        )\n",
    "        \n",
    "        # Calculate additional metrics\n",
    "        train_volatility = calculate_strategy_volatility(\n",
    "            positions_train, forward_returns_train, risk_free_train\n",
    "        )\n",
    "        val_volatility = calculate_strategy_volatility(\n",
    "            positions_val, forward_returns_val, risk_free_val\n",
    "        )\n",
    "        \n",
    "        train_return = calculate_strategy_return(\n",
    "            positions_train, forward_returns_train, risk_free_train\n",
    "        )\n",
    "        val_return = calculate_strategy_return(\n",
    "            positions_val, forward_returns_val, risk_free_val\n",
    "        )\n",
    "        \n",
    "        # Position statistics\n",
    "        avg_position = np.mean(positions_val)\n",
    "        position_std = np.std(positions_val)\n",
    "        \n",
    "        results = {\n",
    "            'model': model_name,\n",
    "            'train_competition_score': train_score,\n",
    "            'val_competition_score': val_score,\n",
    "            'train_volatility': train_volatility,\n",
    "            'val_volatility': val_volatility,\n",
    "            'train_return': train_return,\n",
    "            'val_return': val_return,\n",
    "            'avg_position': avg_position,\n",
    "            'position_std': position_std,\n",
    "            'overfitting': abs(train_score - val_score),\n",
    "            'status': 'success'\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'model': model_name,\n",
    "            'error': str(e),\n",
    "            'train_competition_score': np.nan,\n",
    "            'val_competition_score': np.nan,\n",
    "            'status': 'failed'\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Competition evaluation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d1ddfe",
   "metadata": {},
   "source": [
    "## 5. Model Training and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30ffa5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ COMPETITION-AWARE MODEL TRAINING\n",
      "============================================================\n",
      "\n",
      "üìä TESTING FEATURE SET: ALL_FEATURES\n",
      "--------------------------------------------------\n",
      "   ‚Ä¢ Features: 94 available\n",
      "   ‚ö†Ô∏è Handling 110204 missing values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚Ä¢ Train: 7,192 samples\n",
      "   ‚Ä¢ Validation: 1,798 samples\n",
      "   üîÑ Comp_Ridge... ‚úÖ Score=0.2905, Vol=34.7%, Pos=1.87\n",
      "   üîÑ Comp_Lasso... ‚úÖ Score=0.6225, Vol=13.1%, Pos=0.74\n",
      "   üîÑ Comp_ElasticNet... ‚úÖ Score=0.6225, Vol=13.1%, Pos=0.74\n",
      "   üîÑ Comp_ElasticNet... ‚úÖ Score=0.6225, Vol=13.1%, Pos=0.74\n",
      "   üîÑ Comp_RandomForest... ‚úÖ Score=0.6225, Vol=13.1%, Pos=0.74\n",
      "   üîÑ Comp_RandomForest... ‚úÖ Score=0.3306, Vol=20.8%, Pos=0.47\n",
      "   üîÑ Comp_GradientBoosting... ‚úÖ Score=0.3306, Vol=20.8%, Pos=0.47\n",
      "   üîÑ Comp_GradientBoosting... ‚úÖ Score=0.5046, Vol=23.1%, Pos=0.57\n",
      "   üîÑ Comp_XGBoost... ‚úÖ Score=0.5046, Vol=23.1%, Pos=0.57\n",
      "   üîÑ Comp_XGBoost... ‚úÖ Score=0.3585, Vol=26.2%, Pos=0.77\n",
      "   üîÑ Comp_LightGBM... ‚úÖ Score=0.3585, Vol=26.2%, Pos=0.77\n",
      "   üîÑ Comp_LightGBM... ‚úÖ Score=0.3892, Vol=27.4%, Pos=0.76\n",
      "   üèÜ Best in set: Comp_Lasso (Score=0.6225)\n",
      "\n",
      "üìä TESTING FEATURE SET: VOLATILITY_FOCUSED\n",
      "--------------------------------------------------\n",
      "   ‚Ä¢ Features: 31 available\n",
      "   ‚ö†Ô∏è Handling 64424 missing values\n",
      "   ‚Ä¢ Train: 7,192 samples\n",
      "   ‚Ä¢ Validation: 1,798 samples\n",
      "   üîÑ Comp_Ridge... ‚úÖ Score=0.3425, Vol=29.2%, Pos=1.11\n",
      "   üîÑ Comp_Lasso... ‚úÖ Score=0.3892, Vol=27.4%, Pos=0.76\n",
      "   üèÜ Best in set: Comp_Lasso (Score=0.6225)\n",
      "\n",
      "üìä TESTING FEATURE SET: VOLATILITY_FOCUSED\n",
      "--------------------------------------------------\n",
      "   ‚Ä¢ Features: 31 available\n",
      "   ‚ö†Ô∏è Handling 64424 missing values\n",
      "   ‚Ä¢ Train: 7,192 samples\n",
      "   ‚Ä¢ Validation: 1,798 samples\n",
      "   üîÑ Comp_Ridge... ‚úÖ Score=0.3425, Vol=29.2%, Pos=1.11\n",
      "   üîÑ Comp_Lasso... ‚úÖ Score=0.6225, Vol=13.1%, Pos=0.74\n",
      "   üîÑ Comp_ElasticNet... ‚úÖ Score=0.6225, Vol=13.1%, Pos=0.74\n",
      "   üîÑ Comp_RandomForest... ‚úÖ Score=0.6225, Vol=13.1%, Pos=0.74\n",
      "   üîÑ Comp_ElasticNet... ‚úÖ Score=0.6225, Vol=13.1%, Pos=0.74\n",
      "   üîÑ Comp_RandomForest... ‚úÖ Score=0.4842, Vol=24.6%, Pos=0.64\n",
      "   üîÑ Comp_GradientBoosting... ‚úÖ Score=0.4842, Vol=24.6%, Pos=0.64\n",
      "   üîÑ Comp_GradientBoosting... ‚úÖ Score=0.3471, Vol=29.5%, Pos=1.03\n",
      "   üîÑ Comp_XGBoost... ‚úÖ Score=0.3471, Vol=29.5%, Pos=1.03\n",
      "   üîÑ Comp_XGBoost... ‚úÖ Score=0.2593, Vol=30.4%, Pos=1.16\n",
      "   üîÑ Comp_LightGBM... ‚úÖ Score=0.2593, Vol=30.4%, Pos=1.16\n",
      "   üîÑ Comp_LightGBM... ‚úÖ Score=0.3994, Vol=29.0%, Pos=1.01\n",
      "   üèÜ Best in set: Comp_Lasso (Score=0.6225)\n",
      "\n",
      "üìä TESTING FEATURE SET: PRICE_FOCUSED\n",
      "--------------------------------------------------\n",
      "   ‚Ä¢ Features: 33 available\n",
      "   ‚ö†Ô∏è Handling 14888 missing values\n",
      "   ‚Ä¢ Train: 7,192 samples\n",
      "   ‚Ä¢ Validation: 1,798 samples\n",
      "   üîÑ Comp_Ridge... ‚úÖ Score=0.2056, Vol=16.4%, Pos=0.64\n",
      "   üîÑ Comp_Lasso... ‚úÖ Score=0.3994, Vol=29.0%, Pos=1.01\n",
      "   üèÜ Best in set: Comp_Lasso (Score=0.6225)\n",
      "\n",
      "üìä TESTING FEATURE SET: PRICE_FOCUSED\n",
      "--------------------------------------------------\n",
      "   ‚Ä¢ Features: 33 available\n",
      "   ‚ö†Ô∏è Handling 14888 missing values\n",
      "   ‚Ä¢ Train: 7,192 samples\n",
      "   ‚Ä¢ Validation: 1,798 samples\n",
      "   üîÑ Comp_Ridge... ‚úÖ Score=0.2056, Vol=16.4%, Pos=0.64\n",
      "   üîÑ Comp_Lasso... ‚úÖ Score=0.6225, Vol=13.1%, Pos=0.74\n",
      "   üîÑ Comp_ElasticNet... ‚úÖ Score=0.6225, Vol=13.1%, Pos=0.74\n",
      "   üîÑ Comp_RandomForest... ‚úÖ Score=0.6225, Vol=13.1%, Pos=0.74\n",
      "   üîÑ Comp_ElasticNet... ‚úÖ Score=0.6225, Vol=13.1%, Pos=0.74\n",
      "   üîÑ Comp_RandomForest... ‚úÖ Score=0.6765, Vol=18.8%, Pos=0.59\n",
      "   üîÑ Comp_GradientBoosting... ‚úÖ Score=0.6765, Vol=18.8%, Pos=0.59\n",
      "   üîÑ Comp_GradientBoosting... ‚úÖ Score=0.4774, Vol=23.4%, Pos=0.69\n",
      "   üîÑ Comp_XGBoost... ‚úÖ Score=0.4774, Vol=23.4%, Pos=0.69\n",
      "   üîÑ Comp_XGBoost... ‚úÖ Score=0.6231, Vol=23.8%, Pos=0.71\n",
      "   üîÑ Comp_LightGBM... ‚úÖ Score=0.6231, Vol=23.8%, Pos=0.71\n",
      "   üîÑ Comp_LightGBM... ‚úÖ Score=0.4648, Vol=20.7%, Pos=0.50\n",
      "   üèÜ Best in set: Comp_RandomForest (Score=0.6765)\n",
      "\n",
      "üìä TESTING FEATURE SET: BINARY_SIGNALS\n",
      "--------------------------------------------------\n",
      "   ‚Ä¢ Features: 9 available\n",
      "   ‚Ä¢ Train: 7,192 samples\n",
      "   ‚Ä¢ Validation: 1,798 samples\n",
      "   üîÑ Comp_Ridge... ‚úÖ Score=0.4455, Vol=12.7%, Pos=0.49\n",
      "   üîÑ Comp_Lasso... ‚úÖ Score=0.4648, Vol=20.7%, Pos=0.50\n",
      "   üèÜ Best in set: Comp_RandomForest (Score=0.6765)\n",
      "\n",
      "üìä TESTING FEATURE SET: BINARY_SIGNALS\n",
      "--------------------------------------------------\n",
      "   ‚Ä¢ Features: 9 available\n",
      "   ‚Ä¢ Train: 7,192 samples\n",
      "   ‚Ä¢ Validation: 1,798 samples\n",
      "   üîÑ Comp_Ridge... ‚úÖ Score=0.4455, Vol=12.7%, Pos=0.49\n",
      "   üîÑ Comp_Lasso... ‚úÖ Score=0.6225, Vol=13.1%, Pos=0.74\n",
      "   üîÑ Comp_ElasticNet... ‚úÖ Score=0.6225, Vol=13.1%, Pos=0.74\n",
      "   üîÑ Comp_RandomForest... ‚úÖ Score=0.6225, Vol=13.1%, Pos=0.74\n",
      "   üîÑ Comp_ElasticNet... ‚úÖ Score=0.6225, Vol=13.1%, Pos=0.74\n",
      "   üîÑ Comp_RandomForest... ‚úÖ Score=0.3695, Vol=12.2%, Pos=0.51\n",
      "   üîÑ Comp_GradientBoosting... ‚úÖ Score=0.3695, Vol=12.2%, Pos=0.51\n",
      "   üîÑ Comp_GradientBoosting... ‚úÖ Score=0.3867, Vol=12.8%, Pos=0.52\n",
      "   üîÑ Comp_XGBoost... ‚úÖ Score=0.4213, Vol=13.1%, Pos=0.52\n",
      "   üîÑ Comp_LightGBM... ‚úÖ Score=0.3867, Vol=12.8%, Pos=0.52\n",
      "   üîÑ Comp_XGBoost... ‚úÖ Score=0.4213, Vol=13.1%, Pos=0.52\n",
      "   üîÑ Comp_LightGBM... ‚úÖ Score=0.4507, Vol=12.8%, Pos=0.52\n",
      "   üèÜ Best in set: Comp_Lasso (Score=0.6225)\n",
      "\n",
      "üìä TESTING FEATURE SET: TOP_50\n",
      "--------------------------------------------------\n",
      "   ‚Ä¢ Features: 50 available\n",
      "   ‚ö†Ô∏è Handling 56714 missing values\n",
      "   ‚Ä¢ Train: 7,192 samples\n",
      "   ‚Ä¢ Validation: 1,798 samples\n",
      "   üîÑ Comp_Ridge... ‚úÖ Score=0.2925, Vol=33.1%, Pos=1.63\n",
      "   üîÑ Comp_Lasso... ‚úÖ Score=0.4507, Vol=12.8%, Pos=0.52\n",
      "   üèÜ Best in set: Comp_Lasso (Score=0.6225)\n",
      "\n",
      "üìä TESTING FEATURE SET: TOP_50\n",
      "--------------------------------------------------\n",
      "   ‚Ä¢ Features: 50 available\n",
      "   ‚ö†Ô∏è Handling 56714 missing values\n",
      "   ‚Ä¢ Train: 7,192 samples\n",
      "   ‚Ä¢ Validation: 1,798 samples\n",
      "   üîÑ Comp_Ridge... ‚úÖ Score=0.2925, Vol=33.1%, Pos=1.63\n",
      "   üîÑ Comp_Lasso... ‚úÖ Score=0.6225, Vol=13.1%, Pos=0.74\n",
      "   üîÑ Comp_ElasticNet... ‚úÖ Score=0.6225, Vol=13.1%, Pos=0.74\n",
      "   üîÑ Comp_RandomForest... ‚úÖ Score=0.6225, Vol=13.1%, Pos=0.74\n",
      "   üîÑ Comp_ElasticNet... ‚úÖ Score=0.6225, Vol=13.1%, Pos=0.74\n",
      "   üîÑ Comp_RandomForest... ‚úÖ Score=0.4840, Vol=21.6%, Pos=0.52\n",
      "   üîÑ Comp_GradientBoosting... ‚úÖ Score=0.4840, Vol=21.6%, Pos=0.52\n",
      "   üîÑ Comp_GradientBoosting... ‚úÖ Score=0.5720, Vol=22.4%, Pos=0.60\n",
      "   üîÑ Comp_XGBoost... ‚úÖ Score=0.5720, Vol=22.4%, Pos=0.60\n",
      "   üîÑ Comp_XGBoost... ‚úÖ Score=0.3974, Vol=23.7%, Pos=0.73\n",
      "   üîÑ Comp_LightGBM... ‚úÖ Score=0.3974, Vol=23.7%, Pos=0.73\n",
      "   üîÑ Comp_LightGBM... ‚úÖ Score=0.4495, Vol=24.4%, Pos=0.61\n",
      "   üèÜ Best in set: Comp_Lasso (Score=0.6225)\n",
      "\n",
      "‚úÖ Competition-aware training complete! Tested 35 configurations.\n",
      "‚úÖ Score=0.4495, Vol=24.4%, Pos=0.61\n",
      "   üèÜ Best in set: Comp_Lasso (Score=0.6225)\n",
      "\n",
      "‚úÖ Competition-aware training complete! Tested 35 configurations.\n"
     ]
    }
   ],
   "source": [
    "# Main training loop for competition-aware models\n",
    "print(\"üöÄ COMPETITION-AWARE MODEL TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_results = []\n",
    "best_model_info = {'score': -np.inf, 'model': None, 'features': None}\n",
    "\n",
    "# Test each feature set\n",
    "for set_name, feature_list in feature_sets.items():\n",
    "    print(f\"\\nüìä TESTING FEATURE SET: {set_name.upper()}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Get available features\n",
    "        available_features = [f for f in feature_list if f in df_train_clean.columns]\n",
    "        \n",
    "        if len(available_features) == 0:\n",
    "            print(f\"   ‚ùå No features available for {set_name}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"   ‚Ä¢ Features: {len(available_features)} available\")\n",
    "        \n",
    "        # Prepare feature data\n",
    "        X_full = df_train_clean[available_features].copy()\n",
    "        \n",
    "        # Handle any remaining missing values\n",
    "        missing_count = X_full.isnull().sum().sum()\n",
    "        if missing_count > 0:\n",
    "            print(f\"   ‚ö†Ô∏è Handling {missing_count} missing values\")\n",
    "            X_full = X_full.fillna(X_full.median()).fillna(0)\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = RobustScaler()\n",
    "        X_scaled = scaler.fit_transform(X_full)\n",
    "        \n",
    "        # Time-series split (preserving order)\n",
    "        split_idx = int(len(X_scaled) * 0.8)\n",
    "        \n",
    "        X_train = X_scaled[:split_idx]\n",
    "        X_val = X_scaled[split_idx:]\n",
    "        y_train = y_forward_returns.iloc[:split_idx]\n",
    "        y_val = y_forward_returns.iloc[split_idx:]\n",
    "        \n",
    "        # Target data for competition metric\n",
    "        forward_returns_train = y_forward_returns.iloc[:split_idx]\n",
    "        forward_returns_val = y_forward_returns.iloc[split_idx:]\n",
    "        risk_free_train = y_risk_free_rate.iloc[:split_idx]\n",
    "        risk_free_val = y_risk_free_rate.iloc[split_idx:]\n",
    "        \n",
    "        print(f\"   ‚Ä¢ Train: {len(X_train):,} samples\")\n",
    "        print(f\"   ‚Ä¢ Validation: {len(X_val):,} samples\")\n",
    "        \n",
    "        # Test each model\n",
    "        set_results = []\n",
    "        for model_name, model in models.items():\n",
    "            print(f\"   üîÑ {model_name}...\", end=\" \")\n",
    "            \n",
    "            result = evaluate_competition_model(\n",
    "                model, X_train, y_train, X_val, y_val,\n",
    "                forward_returns_train, risk_free_train,\n",
    "                forward_returns_val, risk_free_val,\n",
    "                model_name\n",
    "            )\n",
    "            \n",
    "            result['feature_set'] = set_name\n",
    "            result['n_features'] = len(available_features)\n",
    "            \n",
    "            if result['status'] == 'failed':\n",
    "                print(f\"‚ùå Failed: {result.get('error', 'Unknown error')[:50]}\")\n",
    "            else:\n",
    "                score = result['val_competition_score']\n",
    "                volatility = result['val_volatility']\n",
    "                avg_pos = result['avg_position']\n",
    "                \n",
    "                print(f\"‚úÖ Score={score:.4f}, Vol={volatility:.1f}%, Pos={avg_pos:.2f}\")\n",
    "                \n",
    "                # Track best model\n",
    "                if score > best_model_info['score']:\n",
    "                    best_model_info.update({\n",
    "                        'score': score,\n",
    "                        'model': model,\n",
    "                        'model_name': model_name,\n",
    "                        'features': available_features,\n",
    "                        'scaler': scaler,\n",
    "                        'feature_set': set_name\n",
    "                    })\n",
    "            \n",
    "            set_results.append(result)\n",
    "            all_results.append(result)\n",
    "        \n",
    "        # Best in this feature set\n",
    "        valid_results = [r for r in set_results if r['status'] == 'success']\n",
    "        if valid_results:\n",
    "            best_in_set = max(valid_results, key=lambda x: x['val_competition_score'])\n",
    "            print(f\"   üèÜ Best in set: {best_in_set['model']} (Score={best_in_set['val_competition_score']:.4f})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Feature set {set_name} failed: {str(e)[:100]}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Competition-aware training complete! Tested {len(all_results)} configurations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cf9792",
   "metadata": {},
   "source": [
    "## 6. Results Analysis and Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9958d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä COMPETITION RESULTS ANALYSIS\n",
      "============================================================\n",
      "‚úÖ Successfully trained 35 models\n",
      "\n",
      "üìà COMPETITION PERFORMANCE SUMMARY:\n",
      "   ‚Ä¢ Average Competition Score: 0.4756\n",
      "   ‚Ä¢ Best Competition Score: 0.6765\n",
      "   ‚Ä¢ Average Volatility: 19.9%\n",
      "   ‚Ä¢ Average Return: 14.4%\n",
      "   ‚Ä¢ Average Position: 0.76\n",
      "\n",
      "üèÜ TOP 5 COMPETITION MODELS:\n",
      "--------------------------------------------------\n",
      "   1. Comp_RandomForest (price_focused)\n",
      "      Competition Score: 0.6765\n",
      "      Strategy Volatility: 18.8%\n",
      "      Strategy Return: 16.5%\n",
      "      Average Position: 0.59\n",
      "      Features: 33\n",
      "\n",
      "   2. Comp_XGBoost (price_focused)\n",
      "      Competition Score: 0.6231\n",
      "      Strategy Volatility: 23.8%\n",
      "      Strategy Return: 21.6%\n",
      "      Average Position: 0.71\n",
      "      Features: 33\n",
      "\n",
      "   3. Comp_Lasso (all_features)\n",
      "      Competition Score: 0.6225\n",
      "      Strategy Volatility: 13.1%\n",
      "      Strategy Return: 11.9%\n",
      "      Average Position: 0.74\n",
      "      Features: 94\n",
      "\n",
      "   4. Comp_ElasticNet (all_features)\n",
      "      Competition Score: 0.6225\n",
      "      Strategy Volatility: 13.1%\n",
      "      Strategy Return: 11.9%\n",
      "      Average Position: 0.74\n",
      "      Features: 94\n",
      "\n",
      "   5. Comp_Lasso (volatility_focused)\n",
      "      Competition Score: 0.6225\n",
      "      Strategy Volatility: 13.1%\n",
      "      Strategy Return: 11.9%\n",
      "      Average Position: 0.74\n",
      "      Features: 31\n",
      "\n",
      "üìä MODEL TYPE COMPARISON (by Competition Score):\n",
      "----------------------------------------\n",
      "   Comp_ElasticNet:\n",
      "      Avg Score: 0.6225 (Best: 0.6225)\n",
      "      Avg Volatility: 13.1%\n",
      "      Avg Return: 11.9%\n",
      "      Avg Position: 0.74\n",
      "      Configurations: 5\n",
      "\n",
      "   Comp_Lasso:\n",
      "      Avg Score: 0.6225 (Best: 0.6225)\n",
      "      Avg Volatility: 13.1%\n",
      "      Avg Return: 11.9%\n",
      "      Avg Position: 0.74\n",
      "      Configurations: 5\n",
      "\n",
      "   Comp_RandomForest:\n",
      "      Avg Score: 0.4690 (Best: 0.6765)\n",
      "      Avg Volatility: 19.6%\n",
      "      Avg Return: 13.7%\n",
      "      Avg Position: 0.55\n",
      "      Configurations: 5\n",
      "\n",
      "   Comp_GradientBoosting:\n",
      "      Avg Score: 0.4576 (Best: 0.5720)\n",
      "      Avg Volatility: 22.2%\n",
      "      Avg Return: 15.9%\n",
      "      Avg Position: 0.68\n",
      "      Configurations: 5\n",
      "\n",
      "   Comp_LightGBM:\n",
      "      Avg Score: 0.4307 (Best: 0.4648)\n",
      "      Avg Volatility: 22.9%\n",
      "      Avg Return: 16.0%\n",
      "      Avg Position: 0.68\n",
      "      Configurations: 5\n",
      "\n",
      "   Comp_XGBoost:\n",
      "      Avg Score: 0.4119 (Best: 0.6231)\n",
      "      Avg Volatility: 23.5%\n",
      "      Avg Return: 15.4%\n",
      "      Avg Position: 0.78\n",
      "      Configurations: 5\n",
      "\n",
      "   Comp_Ridge:\n",
      "      Avg Score: 0.3153 (Best: 0.4455)\n",
      "      Avg Volatility: 25.2%\n",
      "      Avg Return: 15.9%\n",
      "      Avg Position: 1.15\n",
      "      Configurations: 5\n",
      "\n",
      "üîß FEATURE SET COMPARISON:\n",
      "------------------------------\n",
      "   price_focused (33 features):\n",
      "      Avg Score: 0.5275 (Best: 0.6765)\n",
      "      Avg Volatility: 18.5%\n",
      "\n",
      "   top_50 (50 features):\n",
      "      Avg Score: 0.4915 (Best: 0.6225)\n",
      "      Avg Volatility: 21.6%\n",
      "\n",
      "   binary_signals (9 features):\n",
      "      Avg Score: 0.4741 (Best: 0.6225)\n",
      "      Avg Volatility: 12.8%\n",
      "\n",
      "   all_features (94 features):\n",
      "      Avg Score: 0.4455 (Best: 0.6225)\n",
      "      Avg Volatility: 22.6%\n",
      "\n",
      "   volatility_focused (31 features):\n",
      "      Avg Score: 0.4396 (Best: 0.6225)\n",
      "      Avg Volatility: 24.1%\n",
      "\n",
      "üéØ SELECTED BEST MODEL:\n",
      "   ‚Ä¢ Model: Comp_RandomForest\n",
      "   ‚Ä¢ Feature Set: price_focused\n",
      "   ‚Ä¢ Features: 33\n",
      "   ‚Ä¢ Competition Score: 0.6765\n",
      "   ‚Ä¢ Strategy Volatility: 18.77%\n",
      "   ‚Ä¢ Strategy Return: 16.46%\n",
      "   ‚Ä¢ Average Position: 0.592\n",
      "   ‚Ä¢ Position Std: 0.379\n",
      "\n",
      "‚úÖ Competition analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# Analyze competition-aware results\n",
    "print(\"üìä COMPETITION RESULTS ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if len(all_results) == 0:\n",
    "    print(\"‚ùå No successful model runs to analyze!\")\n",
    "else:\n",
    "    # Create results DataFrame\n",
    "    successful_results = [r for r in all_results if r['status'] == 'success']\n",
    "    \n",
    "    if len(successful_results) == 0:\n",
    "        print(\"‚ùå All models failed!\")\n",
    "    else:\n",
    "        results_df = pd.DataFrame(successful_results)\n",
    "        \n",
    "        print(f\"‚úÖ Successfully trained {len(results_df)} models\")\n",
    "        \n",
    "        # Overall performance summary\n",
    "        print(f\"\\nüìà COMPETITION PERFORMANCE SUMMARY:\")\n",
    "        print(f\"   ‚Ä¢ Average Competition Score: {results_df['val_competition_score'].mean():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Best Competition Score: {results_df['val_competition_score'].max():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Average Volatility: {results_df['val_volatility'].mean():.1f}%\")\n",
    "        print(f\"   ‚Ä¢ Average Return: {results_df['val_return'].mean():.1f}%\")\n",
    "        print(f\"   ‚Ä¢ Average Position: {results_df['avg_position'].mean():.2f}\")\n",
    "        \n",
    "        # Top 5 models by competition score\n",
    "        print(f\"\\nüèÜ TOP 5 COMPETITION MODELS:\")\n",
    "        print(\"-\" * 50)\n",
    "        top_models = results_df.nlargest(5, 'val_competition_score')\n",
    "        \n",
    "        for i, (_, row) in enumerate(top_models.iterrows(), 1):\n",
    "            print(f\"   {i}. {row['model']} ({row['feature_set']})\")\n",
    "            print(f\"      Competition Score: {row['val_competition_score']:.4f}\")\n",
    "            print(f\"      Strategy Volatility: {row['val_volatility']:.1f}%\")\n",
    "            print(f\"      Strategy Return: {row['val_return']:.1f}%\")\n",
    "            print(f\"      Average Position: {row['avg_position']:.2f}\")\n",
    "            print(f\"      Features: {row['n_features']}\")\n",
    "            print()\n",
    "        \n",
    "        # Model type comparison\n",
    "        print(f\"üìä MODEL TYPE COMPARISON (by Competition Score):\")\n",
    "        print(\"-\" * 40)\n",
    "        model_comparison = results_df.groupby('model').agg({\n",
    "            'val_competition_score': ['mean', 'max', 'count'],\n",
    "            'val_volatility': 'mean',\n",
    "            'val_return': 'mean',\n",
    "            'avg_position': 'mean'\n",
    "        }).round(4)\n",
    "        \n",
    "        model_comparison.columns = ['avg_score', 'best_score', 'count', 'avg_vol', 'avg_return', 'avg_position']\n",
    "        model_comparison = model_comparison.sort_values('avg_score', ascending=False)\n",
    "        \n",
    "        for model_name, stats in model_comparison.iterrows():\n",
    "            print(f\"   {model_name}:\")\n",
    "            print(f\"      Avg Score: {stats['avg_score']:.4f} (Best: {stats['best_score']:.4f})\")\n",
    "            print(f\"      Avg Volatility: {stats['avg_vol']:.1f}%\")\n",
    "            print(f\"      Avg Return: {stats['avg_return']:.1f}%\")\n",
    "            print(f\"      Avg Position: {stats['avg_position']:.2f}\")\n",
    "            print(f\"      Configurations: {int(stats['count'])}\")\n",
    "            print()\n",
    "        \n",
    "        # Feature set comparison\n",
    "        print(f\"üîß FEATURE SET COMPARISON:\")\n",
    "        print(\"-\" * 30)\n",
    "        feature_comparison = results_df.groupby('feature_set').agg({\n",
    "            'val_competition_score': ['mean', 'max'],\n",
    "            'val_volatility': 'mean',\n",
    "            'n_features': 'first'\n",
    "        }).round(4)\n",
    "        \n",
    "        feature_comparison.columns = ['avg_score', 'best_score', 'avg_vol', 'n_features']\n",
    "        feature_comparison = feature_comparison.sort_values('avg_score', ascending=False)\n",
    "        \n",
    "        for set_name, stats in feature_comparison.iterrows():\n",
    "            print(f\"   {set_name} ({int(stats['n_features'])} features):\")\n",
    "            print(f\"      Avg Score: {stats['avg_score']:.4f} (Best: {stats['best_score']:.4f})\")\n",
    "            print(f\"      Avg Volatility: {stats['avg_vol']:.1f}%\")\n",
    "            print()\n",
    "        \n",
    "        # Best model details\n",
    "        if best_model_info['model'] is not None:\n",
    "            print(f\"üéØ SELECTED BEST MODEL:\")\n",
    "            print(f\"   ‚Ä¢ Model: {best_model_info['model_name']}\")\n",
    "            print(f\"   ‚Ä¢ Feature Set: {best_model_info['feature_set']}\")\n",
    "            print(f\"   ‚Ä¢ Features: {len(best_model_info['features'])}\")\n",
    "            print(f\"   ‚Ä¢ Competition Score: {best_model_info['score']:.4f}\")\n",
    "            \n",
    "            # Show detailed breakdown\n",
    "            best_result = results_df[results_df['val_competition_score'] == best_model_info['score']].iloc[0]\n",
    "            print(f\"   ‚Ä¢ Strategy Volatility: {best_result['val_volatility']:.2f}%\")\n",
    "            print(f\"   ‚Ä¢ Strategy Return: {best_result['val_return']:.2f}%\")\n",
    "            print(f\"   ‚Ä¢ Average Position: {best_result['avg_position']:.3f}\")\n",
    "            print(f\"   ‚Ä¢ Position Std: {best_result['position_std']:.3f}\")\n",
    "            \n",
    "print(f\"\\n‚úÖ Competition analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967a3e0b",
   "metadata": {},
   "source": [
    "## 7. Final Model Training and Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0203901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ FINAL MODEL TRAINING FOR COMPETITION\n",
      "============================================================\n",
      "üèÜ Training Final Model: Comp_RandomForest\n",
      "   ‚Ä¢ Feature Set: price_focused\n",
      "   ‚Ä¢ Features: 33\n",
      "   ‚Ä¢ Validation Score: 0.6765\n",
      "   ‚Ä¢ Handling 14888 missing values\n",
      "\n",
      "üìä Final Data Preparation:\n",
      "   ‚Ä¢ Training samples: 8,990\n",
      "   ‚Ä¢ Test samples: 10\n",
      "   ‚Ä¢ Features used: 33\n",
      "   ‚Ä¢ Features missing in test: 0\n",
      "\n",
      "üöÄ Training final model on full dataset...\n",
      "\n",
      "‚úÖ FINAL COMPETITION PREDICTIONS:\n",
      "==================================================\n",
      "üìä Position Statistics:\n",
      "   ‚Ä¢ Number of predictions: 10\n",
      "   ‚Ä¢ Position range: [0.4784, 0.8218]\n",
      "   ‚Ä¢ Mean position: 0.5128\n",
      "   ‚Ä¢ Position std: 0.1030\n",
      "   ‚Ä¢ Positions > 1.0: 0 (0.0%)\n",
      "   ‚Ä¢ Positions < 1.0: 10 (100.0%)\n",
      "   ‚úÖ All positions within valid range [0, 2]\n",
      "\n",
      "üíæ Competition submission saved to: ../data/predictions/competition_submission.csv\n",
      "   ‚Ä¢ Format: date_id, prediction\n",
      "   ‚Ä¢ Ready for Kaggle submission\n",
      "\n",
      "üìã Sample Predictions:\n",
      " date_id  prediction\n",
      "    8980    0.478435\n",
      "    8981    0.478435\n",
      "    8982    0.821777\n",
      "    8983    0.478435\n",
      "    8984    0.478435\n",
      "    8985    0.478435\n",
      "    8986    0.478435\n",
      "    8987    0.478435\n",
      "    8988    0.478435\n",
      "    8989    0.478435\n",
      "üìä Competition Metric Breakdown:\n",
      "   ‚Ä¢ Strategy Sharpe: 2.5255\n",
      "   ‚Ä¢ Strategy Volatility: 14.94%\n",
      "   ‚Ä¢ Market Volatility: 16.75%\n",
      "   ‚Ä¢ Volatility Penalty: 1.0000\n",
      "   ‚Ä¢ Return Penalty: 1.0000\n",
      "   ‚Ä¢ Adjusted Sharpe: 2.5255\n",
      "\n",
      "üèÜ FINAL TRAINING PERFORMANCE:\n",
      "   ‚Ä¢ Competition Score: 2.5255\n",
      "   ‚Ä¢ Strategy Volatility: 14.94%\n",
      "   ‚Ä¢ Market Volatility: 16.75%\n",
      "   ‚Ä¢ Strategy Return: 49.79%\n",
      "   ‚Ä¢ Volatility Ratio: 0.89\n",
      "\n",
      "============================================================\n",
      "‚úÖ COMPETITION-AWARE MODELING COMPLETE\n",
      "üéØ OPTIMIZED FOR VOLATILITY-ADJUSTED SHARPE RATIO\n",
      "üìà READY FOR KAGGLE SUBMISSION\n",
      "============================================================\n",
      "\n",
      "‚úÖ FINAL COMPETITION PREDICTIONS:\n",
      "==================================================\n",
      "üìä Position Statistics:\n",
      "   ‚Ä¢ Number of predictions: 10\n",
      "   ‚Ä¢ Position range: [0.4784, 0.8218]\n",
      "   ‚Ä¢ Mean position: 0.5128\n",
      "   ‚Ä¢ Position std: 0.1030\n",
      "   ‚Ä¢ Positions > 1.0: 0 (0.0%)\n",
      "   ‚Ä¢ Positions < 1.0: 10 (100.0%)\n",
      "   ‚úÖ All positions within valid range [0, 2]\n",
      "\n",
      "üíæ Competition submission saved to: ../data/predictions/competition_submission.csv\n",
      "   ‚Ä¢ Format: date_id, prediction\n",
      "   ‚Ä¢ Ready for Kaggle submission\n",
      "\n",
      "üìã Sample Predictions:\n",
      " date_id  prediction\n",
      "    8980    0.478435\n",
      "    8981    0.478435\n",
      "    8982    0.821777\n",
      "    8983    0.478435\n",
      "    8984    0.478435\n",
      "    8985    0.478435\n",
      "    8986    0.478435\n",
      "    8987    0.478435\n",
      "    8988    0.478435\n",
      "    8989    0.478435\n",
      "üìä Competition Metric Breakdown:\n",
      "   ‚Ä¢ Strategy Sharpe: 2.5255\n",
      "   ‚Ä¢ Strategy Volatility: 14.94%\n",
      "   ‚Ä¢ Market Volatility: 16.75%\n",
      "   ‚Ä¢ Volatility Penalty: 1.0000\n",
      "   ‚Ä¢ Return Penalty: 1.0000\n",
      "   ‚Ä¢ Adjusted Sharpe: 2.5255\n",
      "\n",
      "üèÜ FINAL TRAINING PERFORMANCE:\n",
      "   ‚Ä¢ Competition Score: 2.5255\n",
      "   ‚Ä¢ Strategy Volatility: 14.94%\n",
      "   ‚Ä¢ Market Volatility: 16.75%\n",
      "   ‚Ä¢ Strategy Return: 49.79%\n",
      "   ‚Ä¢ Volatility Ratio: 0.89\n",
      "\n",
      "============================================================\n",
      "‚úÖ COMPETITION-AWARE MODELING COMPLETE\n",
      "üéØ OPTIMIZED FOR VOLATILITY-ADJUSTED SHARPE RATIO\n",
      "üìà READY FOR KAGGLE SUBMISSION\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Train final model and generate competition submissions\n",
    "print(\"üéØ FINAL MODEL TRAINING FOR COMPETITION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if best_model_info['model'] is None:\n",
    "    print(\"‚ùå No best model found!\")\n",
    "else:\n",
    "    print(f\"üèÜ Training Final Model: {best_model_info['model_name']}\")\n",
    "    print(f\"   ‚Ä¢ Feature Set: {best_model_info['feature_set']}\")\n",
    "    print(f\"   ‚Ä¢ Features: {len(best_model_info['features'])}\")\n",
    "    print(f\"   ‚Ä¢ Validation Score: {best_model_info['score']:.4f}\")\n",
    "    \n",
    "    try:\n",
    "        # Prepare final training data\n",
    "        X_final = df_train_clean[best_model_info['features']].copy()\n",
    "        \n",
    "        # Handle missing values\n",
    "        missing_final = X_final.isnull().sum().sum()\n",
    "        if missing_final > 0:\n",
    "            print(f\"   ‚Ä¢ Handling {missing_final} missing values\")\n",
    "            X_final = X_final.fillna(X_final.median()).fillna(0)\n",
    "        \n",
    "        # Scale features\n",
    "        scaler_final = RobustScaler()\n",
    "        X_final_scaled = scaler_final.fit_transform(X_final)\n",
    "        \n",
    "        # Prepare test data\n",
    "        test_features_available = [f for f in best_model_info['features'] if f in df_test.columns]\n",
    "        X_test_final = df_test[test_features_available].copy()\n",
    "        \n",
    "        print(f\"\\nüìä Final Data Preparation:\")\n",
    "        print(f\"   ‚Ä¢ Training samples: {len(X_final_scaled):,}\")\n",
    "        print(f\"   ‚Ä¢ Test samples: {len(X_test_final):,}\")\n",
    "        print(f\"   ‚Ä¢ Features used: {len(test_features_available)}\")\n",
    "        print(f\"   ‚Ä¢ Features missing in test: {len(best_model_info['features']) - len(test_features_available)}\")\n",
    "        \n",
    "        # Handle missing values in test data\n",
    "        test_missing = X_test_final.isnull().sum().sum()\n",
    "        if test_missing > 0:\n",
    "            print(f\"   ‚Ä¢ Handling {test_missing} missing values in test data\")\n",
    "            X_test_final = X_test_final.fillna(X_test_final.median()).fillna(0)\n",
    "        \n",
    "        # Scale test features\n",
    "        X_test_final_scaled = scaler_final.transform(X_test_final)\n",
    "        \n",
    "        # Train final model\n",
    "        final_model = best_model_info['model']\n",
    "        print(f\"\\nüöÄ Training final model on full dataset...\")\n",
    "        \n",
    "        # Train with competition context\n",
    "        if hasattr(final_model, 'fit') and 'forward_returns' in final_model.fit.__code__.co_varnames:\n",
    "            final_model.fit(X_final_scaled, y_forward_returns, \n",
    "                           forward_returns=y_forward_returns, \n",
    "                           risk_free_rates=y_risk_free_rate)\n",
    "        else:\n",
    "            final_model.fit(X_final_scaled, y_forward_returns)\n",
    "        \n",
    "        # Generate predictions\n",
    "        final_positions = final_model.predict(X_test_final_scaled)\n",
    "        \n",
    "        print(f\"\\n‚úÖ FINAL COMPETITION PREDICTIONS:\")\n",
    "        print(f\"=\" * 50)\n",
    "        print(f\"üìä Position Statistics:\")\n",
    "        print(f\"   ‚Ä¢ Number of predictions: {len(final_positions):,}\")\n",
    "        print(f\"   ‚Ä¢ Position range: [{final_positions.min():.4f}, {final_positions.max():.4f}]\")\n",
    "        print(f\"   ‚Ä¢ Mean position: {final_positions.mean():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Position std: {final_positions.std():.4f}\")\n",
    "        print(f\"   ‚Ä¢ Positions > 1.0: {(final_positions > 1.0).sum()} ({(final_positions > 1.0).mean()*100:.1f}%)\")\n",
    "        print(f\"   ‚Ä¢ Positions < 1.0: {(final_positions < 1.0).sum()} ({(final_positions < 1.0).mean()*100:.1f}%)\")\n",
    "        \n",
    "        # Constraint validation\n",
    "        constraint_violations = (final_positions < 0) | (final_positions > 2)\n",
    "        if constraint_violations.any():\n",
    "            print(f\"   ‚ö†Ô∏è Constraint violations: {constraint_violations.sum()}\")\n",
    "            final_positions = np.clip(final_positions, 0, 2)\n",
    "            print(f\"   ‚úÖ Positions clipped to valid range [0, 2]\")\n",
    "        else:\n",
    "            print(f\"   ‚úÖ All positions within valid range [0, 2]\")\n",
    "        \n",
    "        # Create submission DataFrame\n",
    "        submission_df = pd.DataFrame({\n",
    "            'date_id': df_test['date_id'],\n",
    "            'prediction': final_positions\n",
    "        })\n",
    "        \n",
    "        # Save competition submission\n",
    "        submission_path = '../data/predictions/competition_submission.csv'\n",
    "        import os\n",
    "        os.makedirs('../data/predictions', exist_ok=True)\n",
    "        submission_df.to_csv(submission_path, index=False)\n",
    "        \n",
    "        print(f\"\\nüíæ Competition submission saved to: {submission_path}\")\n",
    "        print(f\"   ‚Ä¢ Format: date_id, prediction\")\n",
    "        print(f\"   ‚Ä¢ Ready for Kaggle submission\")\n",
    "        \n",
    "        # Show sample predictions\n",
    "        print(f\"\\nüìã Sample Predictions:\")\n",
    "        print(submission_df.head(10).to_string(index=False, float_format='%.6f'))\n",
    "        \n",
    "        # Training performance on full dataset\n",
    "        train_positions = final_model.predict(X_final_scaled)\n",
    "        final_train_score = calculate_competition_metric(\n",
    "            train_positions, y_forward_returns, y_risk_free_rate, verbose=True\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nüèÜ FINAL TRAINING PERFORMANCE:\")\n",
    "        print(f\"   ‚Ä¢ Competition Score: {final_train_score:.4f}\")\n",
    "        \n",
    "        # Strategy analysis\n",
    "        strategy_vol = calculate_strategy_volatility(train_positions, y_forward_returns, y_risk_free_rate)\n",
    "        strategy_ret = calculate_strategy_return(train_positions, y_forward_returns, y_risk_free_rate)\n",
    "        market_vol = y_forward_returns.std() * np.sqrt(252) * 100\n",
    "        \n",
    "        print(f\"   ‚Ä¢ Strategy Volatility: {strategy_vol:.2f}%\")\n",
    "        print(f\"   ‚Ä¢ Market Volatility: {market_vol:.2f}%\")\n",
    "        print(f\"   ‚Ä¢ Strategy Return: {strategy_ret:.2f}%\")\n",
    "        print(f\"   ‚Ä¢ Volatility Ratio: {strategy_vol/market_vol:.2f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Final training failed: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"‚úÖ COMPETITION-AWARE MODELING COMPLETE\")\n",
    "print(f\"üéØ OPTIMIZED FOR VOLATILITY-ADJUSTED SHARPE RATIO\")\n",
    "print(f\"üìà READY FOR KAGGLE SUBMISSION\")\n",
    "print(f\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6778709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe989e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf625ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c88f1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251e2e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba8ad74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887780aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cc34ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae76be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c93f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b221f4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a22489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbcb2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b48c540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60a8261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dab472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b11bd70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee47764",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
